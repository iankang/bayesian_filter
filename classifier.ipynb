{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from math import log, sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(path):\n",
    "    for root, dirnames, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            path = os.path.join(root,filename)\n",
    "            \n",
    "            inBody = False\n",
    "            lines = []\n",
    "            \n",
    "            f = io.open(path, 'r', encoding = 'latin1')\n",
    "            for line in f:\n",
    "                if inBody:\n",
    "                    lines.append(line)\n",
    "                elif line == '\\n':\n",
    "                    inBody = True\n",
    "            f.close()\n",
    "            message = '\\n'.join(lines)\n",
    "            yield path, message\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataFrameFromDirectory(path, classification):\n",
    "    rows = []\n",
    "    index = []\n",
    "    for filename, message in read_files(path):\n",
    "        rows.append({'message': message, 'class': classification})\n",
    "        index.append(filename)\n",
    "    return pd.DataFrame(rows, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'message':[],'class':[]})\n",
    "data = data.append(dataFrameFromDirectory('/home/ian/Documents/ham-and-spam-dataset/ham',0))\n",
    "data = data.append(dataFrameFromDirectory('/home/ian/Documents/ham-and-spam-dataset/spam',1))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_mails = data['message'].shape[0]\n",
    "total_mails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def func(df):\n",
    "    soup = BeautifulSoup(df['message'], \"html.parser\").find()\n",
    "    if bool(soup):\n",
    "#         is_html = soup.find('html')\n",
    "#         df['html'] = 'True'\n",
    "        \n",
    "#         if bool(is_html):\n",
    "#             df['mezz'] = 'True'\n",
    "#         soup = BeautifulSoup(df['message'], \"html.parser\")\n",
    "    \n",
    "        text = soup.find_all(text=True)\n",
    "        print(text)\n",
    "        df['message'] = text\n",
    "        \n",
    "        return df['message']\n",
    "    else:\n",
    "        \n",
    "        return df['message'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def generate_blacklist(df):\n",
    "    blacklist = []\n",
    "    soup = BeautifulSoup(df['message'], \"html.parser\")\n",
    "    text = soup.find_all(text=True)\n",
    "    blacklist+=set([t.parent.name for t in text])\n",
    "    return blacklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_html(df, blacklist):\n",
    "    soup = BeautifulSoup(df['message'], \"html.parser\")\n",
    "    \n",
    "    text = soup.get_text()\n",
    "\n",
    "#     output = ''\n",
    "\n",
    "#     for t in text:\n",
    "#         if t not in blacklist:\n",
    "#             output += '{} '.format(t)\n",
    "#     print(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checking_html(df):\n",
    "    count = 0\n",
    "    soup = BeautifulSoup(df['message'], \"html.parser\").find()\n",
    "    if bool(soup):\n",
    "        count+=1\n",
    "    return count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data.reset_index()\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index, test_index = list(), list()\n",
    "for i in range(data['message'].shape[0]):\n",
    "    if np.random.uniform(0,1) < 0.75:\n",
    "        train_index.append(i)\n",
    "    else:\n",
    "        test_index.append(i)\n",
    "        \n",
    "train_data = new_data.loc[train_index]\n",
    "test_data = new_data.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['message']= train_data.apply(func, axis=1)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.apply(checking_html, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black = train_data[train_data.html == 'True'].apply(generate_blacklist,axis = 1)\n",
    "# flat_list = [item for sublist in l for item in sublist]\n",
    "black_list = [item for sublist in black.values for item in sublist]\n",
    "blacklist_set = set(black_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_html = train_data[train_data.html == 'True']\n",
    "train_data['message'] = train_with_html.apply(cleaning_html, blacklist=black_list,axis = 1)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.apply(func, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_html = train_data[train_data.html == 'False']\n",
    "train_no_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_html = train_data[train_data.html == 'True']\n",
    "train_with_html['message'] = train_with_html.apply(cleaning_html, blacklist=black_list,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_html['html']= train_with_html.apply(func, axis=1)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_data = train_data[train_data['html'] == 'True']\n",
    "html_data['message'].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[train_data['mezz']!='False']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.reset_index(inplace=True)\n",
    "train_data.drop(['index'],axis =1, inplace=True)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import BeautifulSoup4\n",
    "\n",
    "bool(BeautifulSoup(train_data['message'], \"html.parser\").find())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_words = ' '.join(list(train_data[train_data['class'] == 1]['message']))\n",
    "spamwc = WordCloud(width = 512, height=512).generate(spam_words)\n",
    "plt.figure(figsize=(10,8), facecolor='k')\n",
    "plt.imshow(spamwc)\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
